<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="TODO">
  <meta name="keywords" content="diffusion, driving, guidance">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Diffusion-ES: Generative Evolutionary Search with Diffusion Models for Trajectory Optimization</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div> -->
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Diffusion-ES: Generative Evolutionary Search with Diffusion Models for <br> Trajectory Optimization</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Brian Yang</a>,</span>
            <span class="author-block">
              <a href="">Huangyuan Su</a>,</span>
            <span class="author-block">
              <a href="">Nikolaos Gkanatsios</a>,
            </span>
            <span class="author-block">
              <a href="">Tsung-Wei Ke</a>,
            </span>
            <br>
            <span class="author-block">
              <a href="">Ayush Jain</a>,
            </span>
            <span class="author-block">
              <a href="">Jeff Schneider</a>,
            </span>
            <span class="author-block">
              <a href="">Katerina Fragkiadaki</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Carnegie Mellon University,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- <br>
              <span class="link-block">
                <i>Code release coming soon!</i>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>
            <div>Code release soon!</div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="method">Diffusion-ES</span> is a flexible test-time trajectory optimization method for 
        arbitrary reward functions that combines generative trajectory models and sampling-based search.
        We show how it can be used for state-of-the-art closed-loop planning and language instruction following in nuPlan.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present <span class="method">Diffusion-ES</span>, a method which combines gradient-free optimization 
            with trajectory denoising to optimize black-box non-differentiable objectives while staying in the data manifold.
          </p>
          <p>
            Reward-gradient guided denoising has been recently proposed to generate trajectories that maximize both a 
            differentiable reward function and the likelihood under the data distribution captured by a diffusion model. 
            Reward-gradient guided denoising requires a differentiable reward function fitted to both clean and noised 
            samples, limiting its applicability as a general trajectory optimizer.
            <span class="method">Diffusion-ES</span> samples trajectories during evolutionary search from a diffusion model and scores them using a 
            black-box reward function. It mutates high-scoring trajectories using a truncated diffusion process that applies
             a small number of noising and denoising steps, allowing for much more efficient exploration of the solution 
             space.
          </p>
          <p>
            <b> Our method can be used to guide any diffusion model at test-time with any black-box reward function with zero retraining,
              zero model architecture assumptions, and only the ability to evaluate clean samples with the reward function.</b>
          </p>
          <p>
            We show that <span class="method">Diffusion-ES</span> achieves state-of-the-art performance on nuPlan, an established closed-loop planning 
            benchmark for autonomous driving. <span class="method">Diffusion-ES</span> outperforms existing sampling-based planners, reactive 
            deterministic or diffusion-based policies, and reward-gradient guidance. Additionally, we show that unlike 
            prior guidance methods, our method can optimize non-differentiable language-shaped reward functions generated 
            by few-shot LLM prompting. When guided by a human teacher that issues instructions to follow, our method can 
            generate novel, highly complex behaviors, such as aggressive lane weaving, which are not present in the 
            training data. This allows us to solve the hardest nuPlan scenarios which are beyond the capabilities of 
            existing trajectory optimization methods and driving policies.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Guided diffusion sampling with evolutionary search</h2>
        <div class="content has-text-justified">
          <p>
            <span class="method">Diffusion-ES</span> leverages gradient-free evolutionary search to 
            perform reward-guided sampling from trained diffusion models.
            An initial population of trajectories is generated by sampling from our diffusion model.
            At each iteration, we score (clean) trajectories with our reward function, select the highest 
            reward samples, and mutate them.
          </p>
        <div style="text-align: center;">
          <img src="./static/images/approach.png" alt="Method diagram", style="max-width: 90%;" />
        </div>
          <p>
            <b>Our key insight is that we can leverage a truncated diffusion process to mutate trajectories
            while staying on the data manifold.</b>
            We can run the first <i>t</i> steps of the forward diffusion process to get noised samples, and then run <i>t</i> steps
            of the reverse diffusion process to denoise the samples again.
            We only need a small fraction of the total number of diffusion steps to perform mutations this way, which 
            makes our sampling-based optimization much more efficient.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Closed-loop planning for driving in nuPlan</h2>
        <!-- <div style="text-align: center;">
          <img src="./static/images/approach.png" alt="Method diagram", style="max-width: 100%;" />
        </div> -->
        <div class="content has-text-justified">
          <p>
            We validate our approach by using black-box planning rewards to guide a trajectory diffusion model.
            Specifically, we adopt the scorer used in <a href="https://arxiv.org/abs/2306.07962">PDM-Closed</a>, with small tweaks to 
            handle more diverse trajectory proposals.
            <span class="method">Diffusion-ES</span> achieves state-of-the-art performance in nuPlan, a closed-loop driving benchmark.
          </p>
        </div>
        <div style="text-align: center;">
          <img src="./static/images/nuplan.png" alt="nuPlan benchmark results", style="max-width: 80%;" />
        </div>
        <div class="content has-text-justified">
          <p>
            Our planner can navigate challenging urban driving scenarios with dense traffic, outperforming prior learning-based methods and
            matching rule-based planners.
            Unlike prior work, our method can navigate environments more assertively, performing unprotected turns and changing lanes without
            dense waypoint guidance.
          </p>
        </div>
        <div>
          <video id="nuplan1" controls loop playsinline width="33%">
            <source src="./static/videos/n1.mp4"
                    type="video/mp4">
          </video>
          <video id="nuplan2" controls loop playsinline width="33%">
            <source src="./static/videos/n2.mp4"
                    type="video/mp4">
          </video>
          <video id="nuplan3" controls loop playsinline width="33%">
            <source src="./static/videos/n3.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Instruction following in nuPlan</h2>
        <div class="content has-text-justified">
          <p>
            <span class="method">Diffusion-ES</span> can be used to optimize arbitrary reward functions at test-time without retraining.
            To highlight this capability, we use few-shot LLM prompting to synthesize novel reward functions which execute langauge instructions,
            and then optimize those reward functions online with our method.
            This allows us to execute arbitrary language instructions without additional training.
          </p>
        </div>
        <div style="text-align: center;">
          <img src="./static/images/langtoreward.png" alt="Language controllability diagram", style="max-width: 80%;" />
        </div>
        <div class="content has-text-justified">
          <p>
            Similar to <a href="https://arxiv.org/abs/2306.08647" >prior work</a>, we expose a Python API which contains <i>reward-shaping</i> methods.
            These methods can be invoked to alter the behavior of the base reward function, e.g., adding a dense lane following reward.
            We provide paired examples of language instructions and corresponding programs which use the provided API.
            Then we can prompt an LLM (GPT-4) with those examples and novel language instructions to automatically generate programs at test-time.
          </p>
        </div>
        <div>
          <video id="longlang" controls loop playsinline width="100%">
            <source src="./static/videos/longlang.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="content has-text-justified">
          <p>
            We also report quantitative performance for instruction following on a suite of language controllability tasks.
            Task success is determined by whether the provided instruction is followed and the scenario objective is accomplished.
          </p>
        </div>
        <div style="text-align: center;">
          <img src="./static/images/instructions.png" alt="Quantative instruction following results", style="max-width: 60%;" />
        </div>
        <div class="content has-text-justified">
          <p>
            We find that although rule-based methods achieve strong results on the original nuPlan benchmark, they struggle with more complex
            scenarios which require changing lanes and driving assertively.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{yang2024diffusiones,
  author    = {Yang, Brian and Su, Huangyuan and Gkanatsios, Nikos and Ke, Tsung-Wei and Jain, Ayush and Schenider, Jeff and Fragiadaki, Katerina},
  title     = {Diffusion-ES: Generative Evolutionary Search with Diffusion Models for Trajectory Optimization},
  journal   = {arXiv},
  year      = {2024},
}
This is not a real BibTeX yet, please do not cite this
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a> -->
      <!-- <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template is taken from <a href="https://github.com/nerfies/nerfies.github.io">here</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
